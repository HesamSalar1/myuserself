#!/bin/bash

# Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ú©â€ŒØ¢Ù¾ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø³ÛŒØ³ØªÙ… Ø±Ø¨Ø§Øªâ€ŒÙ‡Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù…
# Automated Backup Script for Telegram Bots System

set -e

# Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ
BACKUP_DIR="/app/backups"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_NAME="telegram-bots-backup-$TIMESTAMP"
RETENTION_DAYS=${BACKUP_RETENTION_DAYS:-30}

# ØªØ§Ø¨Ø¹ Ù„Ø§Ú¯
log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') [BACKUP] $1"
}

# Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§ÛŒØ±Ú©ØªØ±ÛŒ Ø¨Ú©â€ŒØ¢Ù¾
mkdir -p "$BACKUP_DIR"

log "ğŸ¯ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ú©â€ŒØ¢Ù¾: $BACKUP_NAME"

# Ø¨Ú©â€ŒØ¢Ù¾ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ PostgreSQL
backup_database() {
    log "ğŸ—„ï¸ Ø¨Ú©â€ŒØ¢Ù¾ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ PostgreSQL..."
    
    if [ ! -z "$DATABASE_URL" ]; then
        pg_dump "$DATABASE_URL" > "$BACKUP_DIR/$BACKUP_NAME-database.sql"
        log "âœ… Ø¨Ú©â€ŒØ¢Ù¾ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ú©Ø§Ù…Ù„ Ø´Ø¯"
    else
        log "âš ï¸ DATABASE_URL ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ - Ø§Ø² Ø¨Ú©â€ŒØ¢Ù¾ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ØµØ±Ùâ€ŒÙ†Ø¸Ø± Ø´Ø¯"
    fi
}

# Ø¨Ú©â€ŒØ¢Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ session
backup_sessions() {
    log "ğŸ” Ø¨Ú©â€ŒØ¢Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ session..."
    
    if [ -d "/app/sessions" ]; then
        tar -czf "$BACKUP_DIR/$BACKUP_NAME-sessions.tar.gz" -C /app sessions/
        log "âœ… Ø¨Ú©â€ŒØ¢Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ session Ú©Ø§Ù…Ù„ Ø´Ø¯"
    else
        log "âš ï¸ Ø¯Ø§ÛŒØ±Ú©ØªØ±ÛŒ sessions ÛŒØ§ÙØª Ù†Ø´Ø¯"
    fi
}

# Ø¨Ú©â€ŒØ¢Ù¾ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§
backup_config() {
    log "âš™ï¸ Ø¨Ú©â€ŒØ¢Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ..."
    
    local config_files=(
        "/app/.env"
        "/app/deployment/config.py"
        "/app/unified_bot_launcher.py"
        "/app/monitoring_bot.py"
        "/app/report_bot.py"
    )
    
    mkdir -p "$BACKUP_DIR/config"
    
    for file in "${config_files[@]}"; do
        if [ -f "$file" ]; then
            cp "$file" "$BACKUP_DIR/config/"
            log "ğŸ“„ Ú©Ù¾ÛŒ Ø´Ø¯: $file"
        fi
    done
    
    tar -czf "$BACKUP_DIR/$BACKUP_NAME-config.tar.gz" -C "$BACKUP_DIR" config/
    rm -rf "$BACKUP_DIR/config"
    
    log "âœ… Ø¨Ú©â€ŒØ¢Ù¾ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ú©Ø§Ù…Ù„ Ø´Ø¯"
}

# Ø¨Ú©â€ŒØ¢Ù¾ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…
backup_logs() {
    log "ğŸ“‹ Ø¨Ú©â€ŒØ¢Ù¾ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…..."
    
    if [ -d "/app/logs" ]; then
        # ÙÙ‚Ø· Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ 7 Ø±ÙˆØ² Ø§Ø®ÛŒØ±
        find /app/logs -name "*.log" -mtime -7 -exec tar -czf "$BACKUP_DIR/$BACKUP_NAME-logs.tar.gz" {} +
        log "âœ… Ø¨Ú©â€ŒØ¢Ù¾ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ú©Ø§Ù…Ù„ Ø´Ø¯"
    else
        log "âš ï¸ Ø¯Ø§ÛŒØ±Ú©ØªØ±ÛŒ logs ÛŒØ§ÙØª Ù†Ø´Ø¯"
    fi
}

# Ø¨Ú©â€ŒØ¢Ù¾ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±ÛŒ
backup_user_data() {
    log "ğŸ‘¤ Ø¨Ú©â€ŒØ¢Ù¾ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±ÛŒ..."
    
    if [ -d "/app/data" ]; then
        tar -czf "$BACKUP_DIR/$BACKUP_NAME-data.tar.gz" -C /app data/
        log "âœ… Ø¨Ú©â€ŒØ¢Ù¾ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ú©Ø§Ù…Ù„ Ø´Ø¯"
    else
        log "âš ï¸ Ø¯Ø§ÛŒØ±Ú©ØªØ±ÛŒ data ÛŒØ§ÙØª Ù†Ø´Ø¯"
    fi
}

# Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ S3 (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
upload_to_s3() {
    if [ ! -z "$S3_BACKUP_BUCKET" ] && [ ! -z "$S3_ACCESS_KEY" ] && [ ! -z "$S3_SECRET_KEY" ]; then
        log "â˜ï¸ Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ú©â€ŒØ¢Ù¾ Ø¨Ù‡ S3..."
        
        # Ù†ØµØ¨ AWS CLI Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯
        if ! command -v aws &> /dev/null; then
            pip install awscli
        fi
        
        # ØªÙ†Ø¸ÛŒÙ… credentials
        export AWS_ACCESS_KEY_ID="$S3_ACCESS_KEY"
        export AWS_SECRET_ACCESS_KEY="$S3_SECRET_KEY"
        
        # Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
        for file in "$BACKUP_DIR"/$BACKUP_NAME-*.{sql,tar.gz}; do
            if [ -f "$file" ]; then
                aws s3 cp "$file" "s3://$S3_BACKUP_BUCKET/$(basename "$file")"
                log "â˜ï¸ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯: $(basename "$file")"
            fi
        done
        
        log "âœ… Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ S3 Ú©Ø§Ù…Ù„ Ø´Ø¯"
    else
        log "âš ï¸ Ø§Ø·Ù„Ø§Ø¹Ø§Øª S3 ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ - Ø§Ø² Ø¢Ù¾Ù„ÙˆØ¯ ØµØ±Ùâ€ŒÙ†Ø¸Ø± Ø´Ø¯"
    fi
}

# Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¨Ú©â€ŒØ¢Ù¾â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ
cleanup_old_backups() {
    log "ğŸ§¹ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¨Ú©â€ŒØ¢Ù¾â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ (Ø¨ÛŒØ´ Ø§Ø² $RETENTION_DAYS Ø±ÙˆØ²)..."
    
    find "$BACKUP_DIR" -name "telegram-bots-backup-*" -mtime +$RETENTION_DAYS -delete
    
    # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø§Ø² S3 Ù†ÛŒØ²
    if [ ! -z "$S3_BACKUP_BUCKET" ]; then
        aws s3 ls "s3://$S3_BACKUP_BUCKET/" | while read -r line; do
            createDate=$(echo "$line" | awk '{print $1" "$2}')
            createDate=$(date -d"$createDate" +%s)
            olderThan=$(date -d"$RETENTION_DAYS days ago" +%s)
            
            if [[ $createDate -lt $olderThan ]]; then
                fileName=$(echo "$line" | awk '{print $4}')
                if [[ $fileName == *"telegram-bots-backup-"* ]]; then
                    aws s3 rm "s3://$S3_BACKUP_BUCKET/$fileName"
                    log "ğŸ—‘ï¸ Ø­Ø°Ù Ø´Ø¯ Ø§Ø² S3: $fileName"
                fi
            fi
        done
    fi
    
    log "âœ… Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¨Ú©â€ŒØ¢Ù¾â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ú©Ø§Ù…Ù„ Ø´Ø¯"
}

# Ø§ÛŒØ¬Ø§Ø¯ ÙÙ‡Ø±Ø³Øª Ø¨Ú©â€ŒØ¢Ù¾
create_backup_manifest() {
    log "ğŸ“„ Ø§ÛŒØ¬Ø§Ø¯ ÙÙ‡Ø±Ø³Øª Ø¨Ú©â€ŒØ¢Ù¾..."
    
    cat > "$BACKUP_DIR/$BACKUP_NAME-manifest.json" << EOF
{
    "backup_name": "$BACKUP_NAME",
    "timestamp": "$TIMESTAMP",
    "date": "$(date)",
    "version": "1.0",
    "files": [
EOF

    local first=true
    for file in "$BACKUP_DIR"/$BACKUP_NAME-*.{sql,tar.gz}; do
        if [ -f "$file" ]; then
            if [ "$first" = true ]; then
                first=false
            else
                echo "," >> "$BACKUP_DIR/$BACKUP_NAME-manifest.json"
            fi
            
            local filename=$(basename "$file")
            local filesize=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null || echo "0")
            local checksum=$(sha256sum "$file" | cut -d' ' -f1)
            
            cat >> "$BACKUP_DIR/$BACKUP_NAME-manifest.json" << EOF
        {
            "filename": "$filename",
            "size": $filesize,
            "checksum": "$checksum"
        }
EOF
        fi
    done

    cat >> "$BACKUP_DIR/$BACKUP_NAME-manifest.json" << EOF
    ],
    "total_files": $(ls -1 "$BACKUP_DIR"/$BACKUP_NAME-*.{sql,tar.gz} 2>/dev/null | wc -l),
    "total_size": $(du -sb "$BACKUP_DIR"/$BACKUP_NAME-* 2>/dev/null | awk '{sum += $1} END {print sum}')
}
EOF

    log "âœ… ÙÙ‡Ø±Ø³Øª Ø¨Ú©â€ŒØ¢Ù¾ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯"
}

# Ø§Ø±Ø³Ø§Ù„ Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ
send_notification() {
    local status=$1
    local message=$2
    
    if [ ! -z "$ALERT_WEBHOOK_URL" ]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"ğŸ”„ Backup $status: $message\"}" \
            "$ALERT_WEBHOOK_URL" || true
    fi
    
    if [ ! -z "$NOTIFICATION_EMAIL" ] && [ ! -z "$SMTP_SERVER" ]; then
        # Ø§Ø±Ø³Ø§Ù„ Ø§ÛŒÙ…ÛŒÙ„ (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ mailutils)
        echo "$message" | mail -s "Backup $status - Telegram Bots System" "$NOTIFICATION_EMAIL" || true
    fi
}

# Ø§Ø¬Ø±Ø§ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ú©â€ŒØ¢Ù¾
main() {
    local start_time=$(date +%s)
    
    log "ğŸš€ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ú©â€ŒØ¢Ù¾ Ú©Ø§Ù…Ù„"
    
    # Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø±Ø§Ø­Ù„ Ø¨Ú©â€ŒØ¢Ù¾
    backup_database
    backup_sessions
    backup_config
    backup_logs
    backup_user_data
    
    # Ø§ÛŒØ¬Ø§Ø¯ ÙÙ‡Ø±Ø³Øª
    create_backup_manifest
    
    # Ø¢Ù¾Ù„ÙˆØ¯ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
    upload_to_s3
    
    # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒÙ‡Ø§
    cleanup_old_backups
    
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    local total_size=$(du -sh "$BACKUP_DIR"/$BACKUP_NAME-* 2>/dev/null | awk '{sum += $1} END {print sum}' || echo "0")
    
    log "âœ… ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ú©â€ŒØ¢Ù¾ Ú©Ø§Ù…Ù„ Ø´Ø¯"
    log "â±ï¸ Ù…Ø¯Øª Ø²Ù…Ø§Ù†: ${duration} Ø«Ø§Ù†ÛŒÙ‡"
    log "ğŸ“¦ Ø­Ø¬Ù… Ú©Ù„: $total_size"
    
    # Ø§Ø±Ø³Ø§Ù„ Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ Ù…ÙˆÙÙ‚ÛŒØª
    send_notification "SUCCESS" "Backup completed successfully in ${duration}s. Total size: $total_size"
    
    return 0
}

# Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§
trap 'log "âŒ Ø®Ø·Ø§ Ø¯Ø± ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ú©â€ŒØ¢Ù¾"; send_notification "FAILED" "Backup process failed"; exit 1' ERR

# Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ
if [ "${BASH_SOURCE[0]}" == "${0}" ]; then
    main "$@"
fi